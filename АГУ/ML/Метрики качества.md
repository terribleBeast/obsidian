
Confusion matrix

![](confusion_matrix.png)

## Accuracy

$$Accuracy = \frac{TP+TN}{TP+TN+FP+FN}$$
Определяет долю правильно определенных классов.

Недостатки:
- не учитывает дисбаланс классов: если один класс значительно преобладает над другим, то модель будет смещена в его сторону:
- не дает информацию о типе ошибок модели, например, о количестве ложноположительных и ложноотрицательных результатов, что не позволяет учитывать цену ошибки для разных классов;
- зависит от порога классификации, изменение которого может значительно повлиять на значение точности.

## Precision
$$Precision=\frac{TP}{TP+FP}$$
Характектеризует долю правильно предсказанных положительных классов среди всех образцов, которые модель спрогнозировала как положительный класс. (долю верно предсказанных объектов)

## Recall (True Positive Rate)
$$Recall=\frac{TP}{TP+FN}$$
Доля правильно предсказанных положительных классов среди всех реальных положительных образцов. 

## FPR (False Positive Rate)
Обратная Recall
## F1-score
$$F1\_score = 2*\frac{precision*recall}{precision+recall}$$

F1-score исходит из предположения, что Precision и Recall одинаково важны. Следовательно, если какая-то метрика более значима то добавляем коэффициент $$F1_{\beta}=(1+{\beta}^2*\frac{precision*recall}{{\beta}^2*precision+recall})$$
При $\beta>1$ большее значение придается Recall, при $\beta < 1$ - Precision

## ROC-AUC


**Кривая ROC** – это график, который иллюстрирует производительность классификационной модели при всех возможных порогах классификации.

**Показатель AUC (Area Under the ROC Curve)** — это мера, которая позволяет суммировать производительность модели одним числом, измеряя площадь под кривой ROC. AUC колеблется от 0 до 1.

Важные свойства AUC - это инвариантность к порогу классификации и масштабу предсказаний. Инвариантность к масштабу предсказаний означает, что AUC не зависит от масштаба вероятностей, которые генерирует модель. Например, две модели могут выдавать предсказания в различных масштабах, одна — в виде вероятностей от 0 до 1, а другая — в виде более широкого диапазона значений. Несмотря на эти различия, AUC будет одинаковым, если порядок ранжирования случаев от наиболее вероятного положительного до наиболее вероятного отрицательного сохраняется.

![ROC-AUC](roc_auc.png)


Кривая ROC строится с TPR по оси Y и оси X для различных пороговых значений. Чем ближе кривая находится к верхнему левому углу графика, тем лучше производительность модели. Идеальный классификатор будет проходить через верхний левый угол (TPR = 1, FPR =0). Это означает, что модель имеет высокую чувствительность и низкую частоту ложных срабатываний. Диагональная линия, проходящая через график, представляет собой классификатор, который не лучше случайного угадывания.

## ARI 
$$RI=\frac{2(a+b)}{n(n-1)}$$
a - число пар объектов, имеющие одинаковые метки и находящиеся в одном кластере
b - число пар объектов, имеющие различные метки и находящиеся в разных кластерах.

Характеризует меру согласованности этих разбиений (полученное и исходные). RI выражает схожесть кластеризаций одной и той же выборки. Чтобы этот индекс давал значений близкие к нулю для случайных кластеризаций при любом n и числе кластеров, необходимо нормировать его. Это Adjusted Rand Index
$$ARI=\frac{RI-E[RI]}{max(RI)-E[RI]}$$
Что такое E\[RI]? всегда равен 0,5
## AMI

Данная мера очень похожа на ![$\text{ARI}$](https://habrastorage.org/getpro/habr/formulas/9a8/f50/565/9a8f505650677f969221d6bfb9bc6774.svg). Она также симметрична, не зависит от значений и перестановок меток. Определяется с использованием функции [энтропии](https://en.wikipedia.org/wiki/Entropy_(information_theory)), интерпретируя разбиения выборки, как дискретные распределения (вероятность отнесения к кластеру равна доле объектов в нём). Индекс ![$MI$](https://habrastorage.org/getpro/habr/formulas/cf4/103/0a0/cf41030a02be343fe5703bc8f56af3fa.svg) определяется как [взаимная информация](https://en.wikipedia.org/wiki/Mutual_information) для двух распределений, соответствующих разбиениям выборки на кластеры. Интуитивно, взаимная информация измеряет долю информации, общей для обоих разбиений: насколько информация об одном из них уменьшает неопределенность относительно другого.

Аналогично ![$\text{ARI}$](https://habrastorage.org/getpro/habr/formulas/9a8/f50/565/9a8f505650677f969221d6bfb9bc6774.svg) определяется индекс ![$\text{AMI}$](https://habrastorage.org/getpro/habr/formulas/eaf/fe1/5ba/eaffe15bafa6ba2224581cbea01b4f1c.svg), позволяющий избавиться от роста индекса ![$MI$](https://habrastorage.org/getpro/habr/formulas/cf4/103/0a0/cf41030a02be343fe5703bc8f56af3fa.svg) с увеличением числа классов. Он принимает значения в диапазоне \[0, 1]. Значения, близкие к нулю, говорят о независимости разбиений, а близкие к единице – об их схожести (совпадении при $\text{AMI} = 1$.

## Homogeneity

Определяются с использованием функций [энтропии](https://habr.com/ru/articles/374681/) и условной энтропии, рассматривая разбиения выборки как дискретные распределения 
$$h=1*\frac{H(C|K)}{H(C)},\ c=1-\frac{H(K|C)}{H(K)}$$
K - результат кластеризации
C - истинное разбиение выборки на классы 
h измеряет насколько каждый кластер состоит из объектов одного класса
c - насколько объекта одного класса относятся к одному кластеру

Принимают значения в диапазоне \[0, 1], и большие значения соответствуют более точной кластеризации. **Эти меры не являются нормализованными**. Однако, при числе объектов более 100 и чисел кластеров  менее 10 данная проблема не так явно выражена и может быть проигнорирована. 
Для учета обеих величин h и c одновременно вводится v-мера, как их среднее гармоническое: 
$$v=2\frac{hc}{h+c}$$
Она является симметричной и показывает, насколько две кластеризации схожи между собой.
## Completeness
## V-measure

## Silhouette 
$$s=\frac{b-a}{max(b,a)}$$
*b* - среднее расстояние до объектов из других классов
*a* - среднее расстояние между объектам одного кластера

Показывает насколько среднее расстояние внутри объектов кластера отличается от расстояния до объектов из других кластеров.  Величина лежит в отрезке от \[-1, 1]. 
Значения, близкие к -1, соответствует плохим кластеризациям, то есть b > a, 
Значения, близкие к нулю, говорят, что кластеры пересекаются
Значения, близкие к 1, соответствуют четко выделенным кластерам.